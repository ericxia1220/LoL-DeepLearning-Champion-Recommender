{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "047baca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 19:00:14.910460: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c53a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_path = 'd6yqvmu-5d594ce1-02d7-4e14-af93-5649fbc89a84.jpg'\n",
    "image = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a827f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the @st.cache decorator to cache the model loading\n",
    "\n",
    "def load_model():\n",
    "    model = tf.keras.models.load_model('my_model.h5')\n",
    "    return model\n",
    "\n",
    "# Load your model here\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6dc65a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_encoder(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# In your app.py or any other script where you need the encoder\n",
    "team_position_encoder = load_encoder('teamPosition_encoder.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b57e467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('winPct_standard_scaler.pkl', 'rb') as f:\n",
    "    winPct_standard_scaler = pickle.load(f)\n",
    "\n",
    "# Load the saved MinMaxScaler for the 'winPct' column\n",
    "with open('winPct_minmax_scaler.pkl', 'rb') as f:\n",
    "    winPct_minmax_scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aa9dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Standardize the 'winPct' column using the loaded StandardScaler\n",
    "# winPct = winPct_standard_scaler.transform([[0.54]])\n",
    "\n",
    "# # Normalize the 'winPct' column using the loaded MinMaxScaler\n",
    "# winPct = winPct_minmax_scaler.transform(winPct)\n",
    "# winPct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a158c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "champion_encoded = pd.read_csv('champion_encoded.csv')\n",
    "LOL_data_copy = pd.read_csv('LOL_data_copy.csv')\n",
    "df = pd.read_csv('df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf2ee4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "champion_df = pd.read_csv('champ_info.csv')\n",
    "# create champion dictionary \n",
    "champ_dict = dict((champ, index) for index, champ in enumerate(champion_df['id']))\n",
    "# Create a dictionary that maps champion names to their keys\n",
    "name_to_key = dict((champ, key) for key, champ in enumerate(champion_df['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb58f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(champ1,champ2,champ3,champ4,champ5,champ6,champ7,champ8,champ9,hotstreak,teamPosition,winPct):\n",
    "    #preprocessing\n",
    "    test_text = np.array([champ1,champ2,champ3,champ4,champ5,champ6,champ7,champ8,champ9,hotstreak,teamPosition,winPct])    \n",
    "    champ1_key = name_to_key[champ1]\n",
    "    champ2_key = name_to_key[champ2]\n",
    "    champ3_key = name_to_key[champ3]\n",
    "    champ4_key = name_to_key[champ4]\n",
    "    champ5_key = name_to_key[champ5]\n",
    "    champ6_key = name_to_key[champ6]\n",
    "    champ7_key = name_to_key[champ7]\n",
    "    champ8_key = name_to_key[champ8]\n",
    "    champ9_key = name_to_key[champ9]\n",
    "    if hotstreak == \"Yes\":\n",
    "        hotstreak = 1\n",
    "    else:\n",
    "        hotstreak = 0\n",
    "    teamPosition = team_position_encoder.transform([teamPosition])\n",
    "    test = np.concatenate(([champ1_key,champ2_key,champ3_key,champ4_key,champ5_key,champ6_key,champ7_key,champ8_key,champ9_key,hotstreak], teamPosition,[winPct]))\n",
    "    test_match = np.repeat(test.reshape(1, -1), champion_encoded.shape[0], axis=0)\n",
    "    \n",
    "\n",
    "    # Define the column names for the DataFrame\n",
    "    columns = ['champ1', 'champ2', 'champ3', 'champ4', 'champ5', 'champ6', 'champ7', 'champ8', 'champ9', 'hotstreak', 'teamPosition', 'winPct']\n",
    "\n",
    "    # Create a NumPy array of imputed values for the columns\n",
    "    imputed_values = test_text\n",
    "\n",
    "    # Create a DataFrame with the imputed values repeated 162 times\n",
    "    repeated_df = pd.DataFrame([imputed_values] * 162, columns=columns)\n",
    "  \n",
    "    # champ_df supposed to be 162 champs\n",
    "    prediction = model.predict([test_match, champion_encoded.iloc[:, 1:23]]) \n",
    "    # sort the results, highest prediction first\n",
    "    sorted_index = np.argsort(-prediction,axis=0).reshape(-1).tolist()  #negate to get largest rating first\n",
    "    ## sorted  percentage of winning\n",
    "    sorted_ypu   = prediction[sorted_index]\n",
    "    ##sorted champion list from highest winning to lowest winning\n",
    "    sorted_champion  = champion_encoded.loc[sorted_index]\n",
    "    sorted_champion['Winning Rate'] = sorted_ypu\n",
    "    sorted_champion = pd.concat([sorted_champion, sorted_champion.reset_index(drop=True)], axis=1)\n",
    "    sorted_champion = sorted_champion.loc[:,~sorted_champion.columns.duplicated()]\n",
    "    \n",
    "    \n",
    "    # Merge the dataframes based on the common column\n",
    "    merged_df = pd.merge(sorted_champion, LOL_data_copy, left_on='id', right_on='champion')\n",
    "\n",
    "    # Add the desired columns from LOL_data_copy to sorted_champion\n",
    "    sorted_champion[['difficulty', 'tags', 'hp', 'hpperlevel', 'mp', 'mpperlevel',\n",
    "                     'movespeed', 'armor', 'armorperlevel', 'spellblock',\n",
    "                     'spellblockperlevel', 'attackrange', 'hpregen', 'hpregenperlevel',\n",
    "                     'mpregen', 'mpregenperlevel', 'attackdamage', 'attackdamageperlevel',\n",
    "                     'attackspeedperlevel', 'attackspeed', 'Best_Partner', 'Counters',\n",
    "                     'Countered_by']] = merged_df[['difficulty_y', 'tags',\n",
    "           'hp_y', 'hpperlevel_y', 'mp_y', 'mpperlevel_y', 'movespeed_y',\n",
    "           'armor_y', 'armorperlevel_y', 'spellblock_y', 'spellblockperlevel_y',\n",
    "           'attackrange_y', 'hpregen_y', 'hpregenperlevel_y', 'mpregen_y',\n",
    "           'mpregenperlevel_y', 'attackdamage_y', 'attackdamageperlevel_y',\n",
    "           'attackspeedperlevel_y', 'attackspeed_y', 'Best_Partner', 'Counters',\n",
    "           'Countered_by']]\n",
    "    ##Combine everything together and sort by winning rate\n",
    "    concatenated_df = pd.concat([repeated_df, sorted_champion], axis=1)\n",
    "    columns_to_drop = ['difficulty', 'hp', 'hpperlevel', 'mp', 'mpperlevel',  'movespeed', 'armor', 'armorperlevel', 'spellblock',  'spellblockperlevel', 'attackrange', 'hpregen', 'hpregenperlevel',  'mpregen', 'mpregenperlevel', 'attackdamage', 'attackdamageperlevel',                   'attackspeedperlevel', 'attackspeed']\n",
    "    concatenated_df = concatenated_df.drop(columns=columns_to_drop)\n",
    "    new_column_order = ['id', 'Winning Rate', 'tags', 'Best_Partner', 'Counters', 'Countered_by', 'champ1', 'champ2', 'champ3', 'champ4', 'champ5', 'champ6', 'champ7', 'champ8', 'champ9', 'hotstreak', 'teamPosition', 'winPct']\n",
    "    concatenated_df = concatenated_df[new_column_order]\n",
    "    concatenated_df = concatenated_df.sort_values(by='Winning Rate', ascending=False)\n",
    "    merged_df = concatenated_df.merge(df, left_on='id', right_on='Champion', how='left')\n",
    "    merged_df = merged_df.drop(columns=['Champion'])\n",
    "    # Define a dictionary to map each champion ID to its role\n",
    "    champion_roles = {\n",
    "        'Velkoz': 'Mage',\n",
    "        'Chogath': 'Tank, Mage',\n",
    "        'Nilah': 'Assassin, Mage',\n",
    "        'KSante': 'Assassin',\n",
    "        'Khazix': 'Assassin',\n",
    "        'JarvanIV': 'Fighter, Tank',\n",
    "        'RekSai': 'Fighter, Tank',\n",
    "        'Kaisa': 'Marksman, Assassin',\n",
    "        'Belveth': 'Fighter, Tank',\n",
    "        'Leblanc': 'Assassin, Mage',\n",
    "        'KogMaw': 'Marksman',\n",
    "        'DrMundo': 'Fighter, Tank',\n",
    "        'TwistedFate': 'Mage',\n",
    "        'MissFortune': 'Marksman',\n",
    "        'Zeri': 'Mage, Support',\n",
    "        'Vex': 'Mage',\n",
    "        'Akshan': 'Assassin, Marksman',\n",
    "        'Gwen': 'Fighter',\n",
    "        'LeeSin': 'Fighter',\n",
    "        'Renata': 'Fighter, Tank',\n",
    "        'Nunu': 'Tank, Mage',\n",
    "        'MonkeyKing': 'Fighter',\n",
    "        'MasterYi': 'Assassin',\n",
    "        'XinZhao': 'Fighter, Assassin',\n",
    "        'TahmKench': 'Tank, Support',\n",
    "        'AurelionSol': 'Mage'\n",
    "    }\n",
    "\n",
    "    # Fill in the 'Roles' column based on the 'id' column\n",
    "    merged_df.loc[merged_df['id'].isin(champion_roles.keys()), 'Roles'] = merged_df['id'].map(champion_roles)\n",
    "        # Define the roles for each team position\n",
    "    roles = {\n",
    "        'TOP': ['Mage, Support', 'Mage', \"Mage, Fighter\",'Mage, Assassin', 'Assassin, Mage', 'Marksman, Mage', 'Marksman, Assassin', 'Support'],\n",
    "        'JUNGLE': ['Mage, Assassin', 'Tank, Support', 'Tank, Mage', 'Mage, Support', 'Mage', 'Marksman', 'Marksman, Support', 'Mage, Marksman', 'Support, Mage', 'Support, Tank', 'Marksman, Mage', 'Support, Assassin', 'Marksman, Assassin', 'Support', 'Tank', 'Support, Fighter'],\n",
    "        'MIDDLE': [\"Support, Mage\",'Fighter, Tank', 'Tank, Support', 'Marksman', 'Marksman, Support', 'Mage, Marksman', 'Support, Mage', 'Support, Tank', 'Marksman, Mage', 'Support, Assassin', 'Marksman, Assassin', 'Support', 'Tank', 'Support, Fighter', 'Tank, Mage'],\n",
    "        'BOTTOM': ['Fighter, Tank', 'Mage, Assassin', 'Assassin', 'Tank, Support', 'Support, Mage', 'Tank, Fighter', 'Support, Tank', 'Fighter, Mage', 'Fighter, Assassin', 'Fighter', 'Support', 'Tank', 'Support, Fighter', 'Assassin, Fighter', 'Mage, Fighter', 'Assassin, Mage', 'Fighter, Support', 'Support, Assassin', 'Tank, Mage', 'Mage, Support', 'Mage'],\n",
    "        'UTILITY': ['Fighter, Tank', 'Mage, Assassin', 'Assassin', 'Tank, Mage', 'Mage', 'Marksman', 'Tank, Fighter', 'Fighter, Mage', 'Assassin, Fighter', 'Mage, Fighter', 'Assassin, Mage', 'Marksman, Mage', 'Mage, Marksman', 'Fighter, Assassin', 'Fighter', 'Fighter, Marksman', 'Marksman, Assassin']\n",
    "    }\n",
    "\n",
    "    # Initialize an empty DataFrame to store the sorted rows\n",
    "    sorted_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate through team positions and roles\n",
    "    for position, role_list in roles.items():\n",
    "        # Filter rows based on team position and role\n",
    "        in_role = merged_df[(merged_df['teamPosition'] == position) & (merged_df['Roles'].isin(role_list))]\n",
    "        not_in_role = merged_df[(merged_df['teamPosition'] == position) & (~merged_df['Roles'].isin(role_list))]\n",
    "\n",
    "        # Sort the in_role rows by 'Winning Rate'\n",
    "        sorted_rows = in_role.sort_values(by='Winning Rate', ascending=False)\n",
    "\n",
    "        # Concatenate the sorted_rows and not_in_role DataFrames\n",
    "        position_df = pd.concat([not_in_role, sorted_rows], ignore_index=True)\n",
    "\n",
    "        # Append the position_df to the sorted_df DataFrame\n",
    "        sorted_df = pd.concat([sorted_df, position_df], ignore_index=True)\n",
    "\n",
    "    # Reset the index of the sorted DataFrame\n",
    "    sorted_df.reset_index(drop=True, inplace=True)\n",
    "    ##construct the final dataframe that takes in consideration of the roles of the champion needed \n",
    "    sorted_df.drop(columns=['tags'], inplace=True)\n",
    "    sorted_df = sorted_df[['id', 'Winning Rate', 'Roles', 'Best_Partner', 'Counters', 'Countered_by', 'champ1', 'champ2', 'champ3', 'champ4', 'champ5', 'champ6', 'champ7', 'champ8', 'champ9', 'hotstreak', 'teamPosition', 'winPct']]\n",
    "    sorted_df = sorted_df.rename(columns={'id': 'champion_rec'})\n",
    "    return(sorted_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b867137f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 19:00:22.838 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/Chenjunyu/opt/anaconda3/lib/python3.9/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2023-03-26 19:00:23.054 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "st.title('LoL Champion Recommender Prototype')\n",
    "st.image(image, caption='Your Image Caption', use_column_width=True)\n",
    "st.text_input(\"Enter your Name: \", key=\"name\")\n",
    "st.header('Enter the champions that your teammates have selected: ')\n",
    "\n",
    "champion_selections = {}\n",
    "\n",
    "for i in range(1, 10):\n",
    "    st.subheader(f\"Please select champion {i}\")\n",
    "    left_column, right_column = st.columns(2)\n",
    "    with left_column:\n",
    "        champion_selections[f'champion_{i}'] = st.radio(\n",
    "            'Champion Name:',\n",
    "            np.unique(champion_encoded['id']),\n",
    "            key=f'champion_{i}'\n",
    "        )\n",
    "\n",
    "team_positions = ['TOP', 'JUNGLE', 'MIDDLE', 'BOTTOM', 'UTILITY']\n",
    "\n",
    "selected_team_position = st.select_slider(\"Select team position:\", options=team_positions)\n",
    "\n",
    "hotstreak_options = ['Yes', 'No']\n",
    "selected_hotstreak = st.selectbox(\"Is the player on a hot streak?\", options=hotstreak_options)\n",
    "\n",
    "win_pct = st.slider(\"Win percentage (%)\", min_value=0.0, max_value=100.0, step=0.1)\n",
    "win_pct = win_pct/100\n",
    "\n",
    "if st.button('Recommend top 10 Champions for your game'):\n",
    "    prediction = predict(*champion_selections.values(), selected_hotstreak, selected_team_position, win_pct)\n",
    "    st.write(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec55dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict(\"Darius\",\"Darius\",\"Darius\",\"Darius\",\"Darius\",\"Darius\",\"Darius\",\"Darius\",\"Darius\",\"yes\",\"TOP\",0.53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6767dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ed6a81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0c19f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
